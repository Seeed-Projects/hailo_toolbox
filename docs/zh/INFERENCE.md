# Hailo æ¨¡å‹æ¨ç†æŒ‡å—

æœ¬æ–‡æ¡£å°†æ•™æ‚¨å¦‚ä½•ä½¿ç”¨è½¬æ¢åçš„ Hailo æ¨¡å‹è¿›è¡Œ AI æ¨ç†ã€‚æ— è®ºæ‚¨æ˜¯æƒ³æ£€æµ‹å›¾ç‰‡ä¸­çš„ç‰©ä½“ï¼Œè¿˜æ˜¯åˆ†æè§†é¢‘å†…å®¹ï¼Œè¿™é‡Œéƒ½æœ‰è¯¦ç»†çš„æ•™ç¨‹ã€‚

## ä»€ä¹ˆæ˜¯æ¨¡å‹æ¨ç†ï¼Ÿ

ç®€å•æ¥è¯´ï¼Œæ¨¡å‹æ¨ç†å°±æ˜¯è®© AI æ¨¡å‹"çœ‹"å›¾ç‰‡æˆ–è§†é¢‘ï¼Œç„¶åå‘Šè¯‰æ‚¨å®ƒ"çœ‹åˆ°"äº†ä»€ä¹ˆã€‚æ¯”å¦‚ï¼š
- ğŸš— åœ¨å›¾ç‰‡ä¸­æ‰¾åˆ°æ±½è½¦ã€è¡Œäºº
- ğŸ± è¯†åˆ«å›¾ç‰‡ä¸­çš„çŒ«ã€ç‹—
- ğŸ‘¤ æ£€æµ‹äººä½“å§¿æ€å’ŒåŠ¨ä½œ
- ğŸ­ åˆ†å‰²å›¾åƒä¸­çš„ä¸åŒåŒºåŸŸ

## å‡†å¤‡å·¥ä½œ

### 1. ç¡®ä¿æ‚¨æœ‰ä»¥ä¸‹æ–‡ä»¶

- âœ… **Hailo Toolbox å·²å®‰è£…**
- âœ… **Python ç¯å¢ƒå‡†å¤‡å¥½**
- âœ… **æµ‹è¯•å›¾ç‰‡æˆ–è§†é¢‘**ï¼ˆæˆ–ä½¿ç”¨æ‘„åƒå¤´ï¼‰

### 2. æ£€æŸ¥å®‰è£…

```python
# åœ¨Pythonä¸­éªŒè¯å®‰è£…
from hailo_toolbox.models import ModelsZoo
from hailo_toolbox import create_source
print("Hailo Toolbox å·²æ­£ç¡®å®‰è£…ï¼")
```

## åŸºç¡€æ¨ç†æ•™ç¨‹

### ç¬¬ä¸€æ­¥ï¼šç†è§£åŸºæœ¬ç»“æ„

æ‰€æœ‰çš„æ¨ç†éƒ½éµå¾ªç›¸åŒçš„æ¨¡å¼ï¼š

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo

# 1. åˆ›å»ºè¾“å…¥æº
source = create_source("your_input_source")

# 2. åŠ è½½æ¨¡å‹
model = ModelsZoo.task_type.model_name()

# 3. å¤„ç†æ¯ä¸€å¸§
for img in source:
    results = model.predict(img)
    for result in results:
        # 4. å¤„ç†ç»“æœ
        print("å¤„ç†ç»“æœ...")
```

### ç¬¬äºŒæ­¥ï¼šé€‰æ‹©è¾“å…¥æº

```python
# å›¾ç‰‡æ–‡ä»¶
source = create_source("test_image.jpg")

# è§†é¢‘æ–‡ä»¶
source = create_source("video.mp4")

# æ‘„åƒå¤´ï¼ˆè®¾å¤‡IDé€šå¸¸æ˜¯0ï¼‰
source = create_source(0)

# ç½‘ç»œæ‘„åƒå¤´
source = create_source("rtsp://username:password@192.168.1.100:554/stream")

# å›¾ç‰‡æ–‡ä»¶å¤¹
source = create_source("./images/")

# ç½‘ç»œè§†é¢‘
source = create_source("https://example.com/video.mp4")
```

## æ”¯æŒçš„ä»»åŠ¡ç±»å‹å’Œç¤ºä¾‹

### 1. ç›®æ ‡æ£€æµ‹ï¼ˆæ‰¾ç‰©ä½“ï¼‰

**ç¤ºä¾‹æ–‡ä»¶**: `examples/Hailo_Object_Detection.py`

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
from hailo_toolbox.process.visualization import DetectionVisualization
import cv2

if __name__ == "__main__":
    # åˆ›å»ºè¾“å…¥æº
    source = create_source("test_video.mp4")  # æˆ–ä½¿ç”¨ 0 è¡¨ç¤ºæ‘„åƒå¤´
    
    # åŠ è½½YOLOv8æ£€æµ‹æ¨¡å‹
    inference = ModelsZoo.detection.yolov8s()
    visualization = DetectionVisualization()
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            # å¯è§†åŒ–ç»“æœ
            img = visualization.visualize(img, result)
            cv2.imshow("Detection", img)
            cv2.waitKey(1)
            
            # è·å–æ£€æµ‹ç»“æœ
            boxes = result.get_boxes()      # è¾¹ç•Œæ¡†
            scores = result.get_scores()    # ç½®ä¿¡åº¦
            class_ids = result.get_class_ids()  # ç±»åˆ«ID
            
            print(f"æ£€æµ‹åˆ° {len(result)} ä¸ªç‰©ä½“")
            # æ˜¾ç¤ºå‰5ä¸ªæ£€æµ‹ç»“æœ
            for i in range(min(5, len(result))):
                print(f"  ç‰©ä½“{i}: è¾¹ç•Œæ¡†{boxes[i]}, ç½®ä¿¡åº¦{scores[i]:.3f}, ç±»åˆ«{class_ids[i]}")
```

**èƒ½æ£€æµ‹ä»€ä¹ˆ**ï¼šäººã€è½¦ã€åŠ¨ç‰©ã€æ—¥å¸¸ç‰©å“ç­‰80ç§ç‰©ä½“

**å¯ç”¨æ¨¡å‹**ï¼š
- `ModelsZoo.detection.yolov8n()` - æœ€å¿«é€Ÿåº¦
- `ModelsZoo.detection.yolov8s()` - å¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦
- `ModelsZoo.detection.yolov8m()` - æ›´é«˜ç²¾åº¦
- `ModelsZoo.detection.yolov8l()` - é«˜ç²¾åº¦
- `ModelsZoo.detection.yolov8x()` - æœ€é«˜ç²¾åº¦

### 2. å®ä¾‹åˆ†å‰²ï¼ˆç²¾ç¡®è½®å»“ï¼‰

**ç¤ºä¾‹æ–‡ä»¶**: `examples/Hailo_Instance_Segmentation.py`

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
from hailo_toolbox.process.visualization import SegmentationVisualization
import cv2

if __name__ == "__main__":
    source = create_source("test_video.mp4")
    
    # åŠ è½½YOLOv8åˆ†å‰²æ¨¡å‹
    inference = ModelsZoo.segmentation.yolov8s_seg()
    visualization = SegmentationVisualization()
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            # å¯è§†åŒ–åˆ†å‰²ç»“æœ
            img = visualization.visualize(img, result)
            cv2.imshow("Segmentation", img)
            cv2.waitKey(1)
            
            # è·å–åˆ†å‰²ç»“æœ
            if hasattr(result, "masks") and result.masks is not None:
                print(f"åˆ†å‰²æ©ç å½¢çŠ¶: {result.masks.shape}")
            
            boxes = result.get_boxes_xyxy()  # è¾¹ç•Œæ¡†
            scores = result.get_scores()     # ç½®ä¿¡åº¦
            class_ids = result.get_class_ids()  # ç±»åˆ«ID
```

**èƒ½åšä»€ä¹ˆ**ï¼šä¸ä»…æ‰¾åˆ°ç‰©ä½“ï¼Œè¿˜èƒ½ç”»å‡ºç²¾ç¡®çš„è½®å»“

**å¯ç”¨æ¨¡å‹**ï¼š
- `ModelsZoo.segmentation.yolov8n_seg()` - å¿«é€Ÿåˆ†å‰²
- `ModelsZoo.segmentation.yolov8s_seg()` - æ ‡å‡†åˆ†å‰²
- `ModelsZoo.segmentation.yolov8m_seg()` - é«˜ç²¾åº¦åˆ†å‰²

### 3. å§¿æ€ä¼°è®¡ï¼ˆäººä½“å…³é”®ç‚¹ï¼‰

**ç¤ºä¾‹æ–‡ä»¶**: `examples/Hailo_Pose_Estimation.py`

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
from hailo_toolbox.process.visualization import KeypointVisualization
import cv2

if __name__ == "__main__":
    source = create_source("test_video.mp4")
    
    # åŠ è½½YOLOv8å§¿æ€ä¼°è®¡æ¨¡å‹
    inference = ModelsZoo.pose_estimation.yolov8s_pose()
    visualization = KeypointVisualization()
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            # å¯è§†åŒ–å§¿æ€ç»“æœ
            img = visualization.visualize(img, result)
            cv2.imshow("Pose Estimation", img)
            cv2.waitKey(1)
            
            print(f"æ£€æµ‹åˆ° {len(result)} ä¸ªäºº")
            # æ˜¾ç¤ºå‰3ä¸ªäººçš„å§¿æ€ä¿¡æ¯
            for i, person in enumerate(result):
                if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    break
                keypoints = person.get_keypoints()  # å…³é”®ç‚¹åæ ‡
                score = person.get_score()          # äººä½“ç½®ä¿¡åº¦
                boxes = person.get_boxes()          # è¾¹ç•Œæ¡†
                
                print(f"  äºº{i}: {len(keypoints)}ä¸ªå…³é”®ç‚¹, ç½®ä¿¡åº¦{score[0]:.3f}")
```

**èƒ½åšä»€ä¹ˆ**ï¼šæ£€æµ‹äººä½“17ä¸ªå…³é”®ç‚¹ï¼Œåˆ†æäººçš„å§¿æ€å’ŒåŠ¨ä½œ

**å¯ç”¨æ¨¡å‹**ï¼š
- `ModelsZoo.pose_estimation.yolov8s_pose()` - æ ‡å‡†å§¿æ€ä¼°è®¡
- `ModelsZoo.pose_estimation.yolov8m_pose()` - é«˜ç²¾åº¦å§¿æ€ä¼°è®¡

### 4. å›¾åƒåˆ†ç±»ï¼ˆè¯†åˆ«ä¸»è¦ç‰©ä½“ï¼‰

**ç¤ºä¾‹æ–‡ä»¶**: `examples/Hailo_Classification.py`

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo

if __name__ == "__main__":
    source = create_source("test_image.jpg")
    
    # åŠ è½½åˆ†ç±»æ¨¡å‹
    inference = ModelsZoo.classification.resnet18()
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            # è·å–åˆ†ç±»ç»“æœ
            class_name = result.get_class_name()        # æœ€å¯èƒ½çš„ç±»åˆ«
            confidence = result.get_score()             # ç½®ä¿¡åº¦
            top5_names = result.get_top_5_class_names() # å‰5ä¸ªç±»åˆ«
            top5_scores = result.get_top_5_scores()     # å‰5ä¸ªåˆ†æ•°
            
            print(f"åˆ†ç±»ç»“æœ: {class_name} (ç½®ä¿¡åº¦: {confidence:.3f})")
            print(f"å‰5ä¸ªç±»åˆ«: {top5_names}")
            print(f"å‰5ä¸ªåˆ†æ•°: {[f'{score:.3f}' for score in top5_scores]}")
```

**å¯ç”¨æ¨¡å‹**ï¼š
- `ModelsZoo.classification.mobilenetv1()` - è½»é‡çº§åˆ†ç±»
- `ModelsZoo.classification.resnet18()` - ç»å…¸åˆ†ç±»æ¨¡å‹

### 5. äººè„¸æ£€æµ‹

**ç¤ºä¾‹æ–‡ä»¶**: `examples/Hailo_Face_Detection.py`

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
import cv2

def visualize_face_detection(img, boxes, scores, landmarks):
    for i in range(len(boxes)):
        box = boxes[i]
        score = scores[i]
        # ç»˜åˆ¶äººè„¸æ¡†
        cv2.rectangle(img, (int(box[0]), int(box[1])), 
                     (int(box[2]), int(box[3])), (0, 255, 0), 2)
    return img

if __name__ == "__main__":
    source = create_source("test_video.mp4")
    
    # åŠ è½½äººè„¸æ£€æµ‹æ¨¡å‹
    inference = ModelsZoo.face_detection.scrfd_10g()
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            print(f"æ£€æµ‹åˆ° {len(result)} å¼ äººè„¸")
            
            boxes = result.get_boxes(pixel_coords=True)      # äººè„¸æ¡†
            scores = result.get_scores()                     # ç½®ä¿¡åº¦
            landmarks = result.get_landmarks(pixel_coords=True)  # é¢éƒ¨å…³é”®ç‚¹
            
            img = visualize_face_detection(img, boxes, scores, landmarks)
            cv2.imshow("Face Detection", img)
            cv2.waitKey(1)
```

**å¯ç”¨æ¨¡å‹**ï¼š
- `ModelsZoo.face_detection.scrfd_10g()` - é«˜ç²¾åº¦äººè„¸æ£€æµ‹
- `ModelsZoo.face_detection.scrfd_2_5g()` - å¹³è¡¡æ€§èƒ½
- `ModelsZoo.face_detection.scrfd_500m()` - å¿«é€Ÿæ£€æµ‹
- `ModelsZoo.face_detection.retinaface_mbnet()` - è½»é‡çº§æ£€æµ‹

### 6. æ·±åº¦ä¼°è®¡

**ç¤ºä¾‹æ–‡ä»¶**: `examples/Hailo_Depth_Estimation.py`

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
import cv2

if __name__ == "__main__":
    source = create_source("test_video.mp4")
    
    # åŠ è½½æ·±åº¦ä¼°è®¡æ¨¡å‹
    inference = ModelsZoo.depth_estimation.fast_depth()
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            depth_map = result.get_depth()                    # åŸå§‹æ·±åº¦å›¾
            depth_normalized = result.get_depth_normalized()  # å½’ä¸€åŒ–æ·±åº¦å›¾
            original_shape = result.get_original_shape()      # åŸå§‹å›¾åƒå°ºå¯¸
            
            cv2.imshow("Depth Estimation", depth_normalized)
            cv2.waitKey(1)
            
            print(f"æ·±åº¦å›¾å½¢çŠ¶: {depth_map.shape}")
            print(f"æ·±åº¦å€¼èŒƒå›´: [{depth_map.min():.3f}, {depth_map.max():.3f}]")
            print(f"åŸå§‹å›¾åƒå°ºå¯¸: {original_shape}")
```

**å¯ç”¨æ¨¡å‹**ï¼š
- `ModelsZoo.depth_estimation.fast_depth()` - å¿«é€Ÿæ·±åº¦ä¼°è®¡
- `ModelsZoo.depth_estimation.scdepthv3()` - é«˜ç²¾åº¦æ·±åº¦ä¼°è®¡

## å®é™…ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šå®¶åº­å®‰é˜²ç›‘æ§

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
from hailo_toolbox.process.visualization import DetectionVisualization
import cv2
import datetime

def security_monitoring():
    # ä½¿ç”¨æ‘„åƒå¤´
    source = create_source(0)
    inference = ModelsZoo.detection.yolov8s()
    visualization = DetectionVisualization()
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            # æ£€æŸ¥æ˜¯å¦æœ‰äºº
            class_ids = result.get_class_ids()
            if 0 in class_ids:  # 0 è¡¨ç¤ºäºº
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                cv2.imwrite(f"security_alert_{timestamp}.jpg", img)
                print(f"å®‰å…¨è­¦æŠ¥ï¼æ£€æµ‹åˆ°å…¥ä¾µè€… - {timestamp}")
            
            img = visualization.visualize(img, result)
            cv2.imshow("Security Monitor", img)
            cv2.waitKey(1)

if __name__ == "__main__":
    security_monitoring()
```

### ç¤ºä¾‹ 2ï¼šäº¤é€šç›‘æ§åˆ†æ

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
import cv2

def traffic_analysis():
    source = create_source("traffic_video.mp4")
    inference = ModelsZoo.detection.yolov8m()
    
    vehicle_classes = [2, 3, 5, 7]  # æ±½è½¦ã€æ‘©æ‰˜è½¦ã€å…¬äº¤è½¦ã€å¡è½¦
    
    for img in source:
        results = inference.predict(img)
        for result in results:
            class_ids = result.get_class_ids()
            boxes = result.get_boxes()
            
            vehicle_count = sum(1 for class_id in class_ids if class_id in vehicle_classes)
            person_count = sum(1 for class_id in class_ids if class_id == 0)
            
            print(f"è½¦è¾†æ•°é‡: {vehicle_count}, è¡Œäººæ•°é‡: {person_count}")
            
            # å¯è§†åŒ–
            for i, (box, class_id) in enumerate(zip(boxes, class_ids)):
                if class_id in vehicle_classes or class_id == 0:
                    color = (0, 255, 0) if class_id in vehicle_classes else (255, 0, 0)
                    cv2.rectangle(img, (int(box[0]), int(box[1])), 
                                (int(box[2]), int(box[3])), color, 2)
            
            cv2.imshow("Traffic Analysis", img)
            cv2.waitKey(1)

if __name__ == "__main__":
    traffic_analysis()
```

### ç¤ºä¾‹ 3ï¼šæ‰¹é‡å›¾ç‰‡å¤„ç†

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
import cv2
import os

def batch_image_processing():
    # å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
    source = create_source("./product_photos/")
    inference = ModelsZoo.detection.yolov8n()
    
    os.makedirs("./detection_results", exist_ok=True)
    
    for i, img in enumerate(source):
        results = inference.predict(img)
        for result in results:
            boxes = result.get_boxes()
            scores = result.get_scores()
            class_ids = result.get_class_ids()
            
            # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
            for box, score, class_id in zip(boxes, scores, class_ids):
                cv2.rectangle(img, (int(box[0]), int(box[1])), 
                            (int(box[2]), int(box[3])), (0, 255, 0), 2)
                cv2.putText(img, f"Class{class_id}: {score:.2f}", 
                          (int(box[0]), int(box[1])-10), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # ä¿å­˜ç»“æœ
            cv2.imwrite(f"./detection_results/result_{i:04d}.jpg", img)
            print(f"å¤„ç†å®Œæˆ: å›¾ç‰‡ {i}, æ£€æµ‹åˆ° {len(result)} ä¸ªç‰©ä½“")

if __name__ == "__main__":
    batch_image_processing()
```

## å¸¸è§é—®é¢˜è§£å†³

### Q1: æç¤º"æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶"

**é—®é¢˜**: æ¨¡å‹ä¸‹è½½å¤±è´¥æˆ–ç½‘ç»œé—®é¢˜

**è§£å†³æ–¹æ³•**:
```python
# æ£€æŸ¥ç½‘ç»œè¿æ¥
import requests
try:
    response = requests.get("https://www.google.com", timeout=5)
    print("ç½‘ç»œè¿æ¥æ­£å¸¸")
except:
    print("ç½‘ç»œè¿æ¥æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")

# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼‰
from hailo_toolbox.models import ModelsZoo
model = ModelsZoo.detection.yolov8n()  # è¿™ä¼šå°è¯•ä¸‹è½½æ¨¡å‹
```

### Q2: æ‘„åƒå¤´æ— æ³•æ‰“å¼€

**é—®é¢˜**: `Cannot open camera device 0`

**è§£å†³æ–¹æ³•**:
```python
import cv2

# æµ‹è¯•ä¸åŒçš„æ‘„åƒå¤´ID
for i in range(5):
    cap = cv2.VideoCapture(i)
    if cap.isOpened():
        print(f"æ‘„åƒå¤´ {i} å¯ç”¨")
        cap.release()
    else:
        print(f"æ‘„åƒå¤´ {i} ä¸å¯ç”¨")

# ä½¿ç”¨å¯ç”¨çš„æ‘„åƒå¤´ID
source = create_source(0)  # æˆ–è€…ä½¿ç”¨æ‰¾åˆ°çš„å¯ç”¨ID
```

### Q3: æ¨ç†ç»“æœä¸å‡†ç¡®

**å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ³•**:

1. **è¾“å…¥å›¾åƒè´¨é‡é—®é¢˜**
```python
import cv2

# æ£€æŸ¥å›¾åƒè´¨é‡
def check_image_quality(img):
    if img is None:
        print("å›¾åƒä¸ºç©º")
        return False
    
    height, width = img.shape[:2]
    if height < 100 or width < 100:
        print(f"å›¾åƒå¤ªå°: {width}x{height}")
        return False
    
    # æ£€æŸ¥äº®åº¦
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    brightness = gray.mean()
    if brightness < 30:
        print(f"å›¾åƒå¤ªæš—: äº®åº¦ {brightness}")
    elif brightness > 200:
        print(f"å›¾åƒå¤ªäº®: äº®åº¦ {brightness}")
    
    return True
```

2. **é€‰æ‹©åˆé€‚çš„æ¨¡å‹**
```python
# æ ¹æ®éœ€æ±‚é€‰æ‹©æ¨¡å‹
# é€Ÿåº¦ä¼˜å…ˆï¼šyolov8n
# å¹³è¡¡ï¼šyolov8s
# ç²¾åº¦ä¼˜å…ˆï¼šyolov8m, yolov8l, yolov8x

inference = ModelsZoo.detection.yolov8s()  # æ¨èçš„å¹³è¡¡é€‰æ‹©
```

### Q4: æ¨ç†é€Ÿåº¦å¾ˆæ…¢

**ä¼˜åŒ–å»ºè®®**:

1. **ä½¿ç”¨æ›´å°çš„æ¨¡å‹**
```python
# ä½¿ç”¨æœ€å¿«çš„æ¨¡å‹
inference = ModelsZoo.detection.yolov8n()  # è€Œä¸æ˜¯ yolov8x
```

2. **é™ä½è¾“å…¥åˆ†è¾¨ç‡**
```python
import cv2

def resize_frame(img, max_size=640):
    height, width = img.shape[:2]
    if max(height, width) > max_size:
        scale = max_size / max(height, width)
        new_width = int(width * scale)
        new_height = int(height * scale)
        img = cv2.resize(img, (new_width, new_height))
    return img

# åœ¨æ¨ç†å‰è°ƒæ•´å›¾åƒå¤§å°
for img in source:
    img = resize_frame(img)
    results = inference.predict(img)
    # ...
```

3. **è·³å¸§å¤„ç†**
```python
frame_skip = 2  # æ¯2å¸§å¤„ç†ä¸€æ¬¡
frame_count = 0

for img in source:
    frame_count += 1
    if frame_count % frame_skip != 0:
        continue
    
    results = inference.predict(img)
    # å¤„ç†ç»“æœ...
```

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

```python
# æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©æ¨¡å‹
# å®æ—¶åº”ç”¨ï¼šé€‰æ‹©è¾ƒå°çš„æ¨¡å‹
inference = ModelsZoo.detection.yolov8n()

# ç¦»çº¿åˆ†æï¼šå¯ä»¥é€‰æ‹©æ›´å¤§çš„æ¨¡å‹
inference = ModelsZoo.detection.yolov8x()
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–

```python
# å¯¹äºå›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œä¸éœ€è¦å®æ—¶æ˜¾ç¤º
source = create_source("./images/")
inference = ModelsZoo.detection.yolov8s()

for i, img in enumerate(source):
    results = inference.predict(img)
    # åªå¤„ç†ç»“æœï¼Œä¸æ˜¾ç¤º
    for result in results:
        # ä¿å­˜æˆ–è®°å½•ç»“æœ
        print(f"å›¾ç‰‡ {i}: æ£€æµ‹åˆ° {len(result)} ä¸ªç‰©ä½“")
```

### 3. å†…å­˜ç®¡ç†

```python
import gc

# å®šæœŸæ¸…ç†å†…å­˜
frame_count = 0
for img in source:
    results = inference.predict(img)
    # å¤„ç†ç»“æœ...
    
    frame_count += 1
    if frame_count % 100 == 0:
        gc.collect()  # æ¯100å¸§æ¸…ç†ä¸€æ¬¡å†…å­˜
```

## ç†è§£æ¨ç†ç»“æœ

### ç›®æ ‡æ£€æµ‹ç»“æœ

```python
for result in results:
    boxes = result.get_boxes()          # è¾¹ç•Œæ¡† [x1, y1, x2, y2]
    scores = result.get_scores()        # ç½®ä¿¡åº¦åˆ†æ•° [0.0-1.0]
    class_ids = result.get_class_ids()  # ç±»åˆ«ID [0-79 for COCO]
    
    print(f"æ£€æµ‹åˆ° {len(result)} ä¸ªç‰©ä½“")
    for i in range(len(result)):
        print(f"ç‰©ä½“ {i}: ç±»åˆ«{class_ids[i]}, ç½®ä¿¡åº¦{scores[i]:.3f}")
```

### åˆ†å‰²ç»“æœ

```python
for result in results:
    if hasattr(result, "masks") and result.masks is not None:
        masks = result.masks            # åˆ†å‰²æ©ç 
        print(f"æ©ç å½¢çŠ¶: {masks.shape}")
    
    boxes = result.get_boxes_xyxy()     # è¾¹ç•Œæ¡†
    scores = result.get_scores()        # ç½®ä¿¡åº¦
```

### å§¿æ€ä¼°è®¡ç»“æœ

```python
for result in results:
    for person in result:
        keypoints = person.get_keypoints()  # 17ä¸ªå…³é”®ç‚¹åæ ‡
        score = person.get_score()          # äººä½“æ£€æµ‹ç½®ä¿¡åº¦
        boxes = person.get_boxes()          # äººä½“è¾¹ç•Œæ¡†
        
        print(f"å…³é”®ç‚¹æ•°é‡: {len(keypoints)}")
        print(f"äººä½“ç½®ä¿¡åº¦: {score}")
```

## æ€»ç»“

ä½¿ç”¨ Hailo Toolbox è¿›è¡Œæ¨¡å‹æ¨ç†çš„åŸºæœ¬æ­¥éª¤ï¼š

1. **åˆ›å»ºè¾“å…¥æº** - ä½¿ç”¨ `create_source()` å‡½æ•°
2. **åŠ è½½æ¨¡å‹** - ä» `ModelsZoo` é€‰æ‹©åˆé€‚çš„æ¨¡å‹
3. **å¤„ç†æ•°æ®** - éå†è¾“å…¥æºçš„æ¯ä¸€å¸§
4. **è·å–ç»“æœ** - è°ƒç”¨æ¨¡å‹çš„ `predict()` æ–¹æ³•
5. **å¤„ç†è¾“å‡º** - ä½¿ç”¨ç»“æœå¯¹è±¡çš„å„ç§æ–¹æ³•è·å–æ•°æ®

### å¸¸ç”¨ä»£ç æ¨¡æ¿

```python
from hailo_toolbox import create_source
from hailo_toolbox.models import ModelsZoo
import cv2

# åŸºç¡€æ¨¡æ¿
def basic_inference():
    source = create_source("your_input")
    model = ModelsZoo.task_type.model_name()
    
    for img in source:
        results = model.predict(img)
        for result in results:
            # å¤„ç†ç»“æœ
            print("æ¨ç†å®Œæˆ")

# å¸¦å¯è§†åŒ–çš„æ¨¡æ¿
def inference_with_visualization():
    source = create_source("your_input")
    model = ModelsZoo.detection.yolov8s()
    
    for img in source:
        results = model.predict(img)
        for result in results:
            # ç»˜åˆ¶ç»“æœ
            boxes = result.get_boxes()
            for box in boxes:
                cv2.rectangle(img, (int(box[0]), int(box[1])), 
                            (int(box[2]), int(box[3])), (0, 255, 0), 2)
            
            cv2.imshow("Results", img)
            cv2.waitKey(1)

if __name__ == "__main__":
    basic_inference()
```

ç°åœ¨æ‚¨å·²ç»æŒæ¡äº† Hailo æ¨¡å‹æ¨ç†çš„å®Œæ•´æŠ€èƒ½ï¼å‚è€ƒ `examples/` æ–‡ä»¶å¤¹ä¸­çš„å…·ä½“ç¤ºä¾‹å¼€å§‹æ‚¨çš„ AI ä¹‹æ—…å§ï¼

---

**ç›¸å…³æ–‡æ¡£**: 
- [æ¨¡å‹è½¬æ¢æŒ‡å—](CONVERT.md) - å­¦ä¹ å¦‚ä½•è½¬æ¢æ¨¡å‹
- [å¼€å‘è€…æ–‡æ¡£](DEV.md) - è‡ªå®šä¹‰æ¨¡å‹å¼€å‘
- [å¿«é€Ÿå¼€å§‹](GET_STAR.md) - å®Œæ•´çš„å®‰è£…å’Œä½¿ç”¨æŒ‡å—
- [ç¤ºä¾‹ä»£ç ](../examples/) - å®Œæ•´çš„æ¨ç†ç¤ºä¾‹
